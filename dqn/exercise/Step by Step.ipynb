{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "State shape:  (8,)\n",
      "Number of actions:  4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(0)\n",
    "print('State shape: ', env.observation_space.shape)\n",
    "print('Number of actions: ', env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_window = deque(maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed  = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_local = QNetwork(8, 4, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_target = QNetwork(8, 4, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x10bb21518>\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "print(dqn_local.parameters())\n",
    "optimizer = optim.Adam(dqn_local.parameters(), lr=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = deque(maxlen=int(1e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.91564178e-04,  9.42304904e-01, -5.99357188e-02,  1.12770955e-01,\n",
       "        6.92289264e-04,  1.35763153e-02,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0006,  0.9423, -0.0599,  0.1128,  0.0007,  0.0136,  0.0000,\n",
      "          0.0000]])\n"
     ]
    }
   ],
   "source": [
    "state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QNetwork(\n",
       "  (fc1): Linear(in_features=8, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn_local.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-02 *\n",
      "       [[-0.6673,  5.7288, -9.8835,  5.0341]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    action_values = dqn_local(state)\n",
    "    print(action_values)\n",
    "    print(np.argmax(action_values.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6558345055531296\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "r = random.random()\n",
    "print(r)\n",
    "\n",
    "if r > eps: \n",
    "    action_id = np.argmax(action_values.data)\n",
    "else:\n",
    "    action_id = random.choice(np.arange(4))\n",
    "\n",
    "print(action_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00118332  0.94361125 -0.05985444  0.08708715  0.00136317  0.01341959\n",
      "  0.          0.        ]\n",
      "2.00584477863886\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "next_state, reward, done, _ = env.step(action_id)\n",
    "print(next_state)\n",
    "print(reward)\n",
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[-0.0006,  0.9423, -0.0599,  0.1128,  0.0007,  0.0136,  0.0000,\n",
      "          0.0000]]), 0, 2.00584477863886, array([-0.00118332,  0.94361125, -0.05985444,  0.08708715,  0.00136317,\n",
      "        0.01341959,  0.        ,  0.        ]), False]\n",
      "deque([[tensor([[-0.0006,  0.9423, -0.0599,  0.1128,  0.0007,  0.0136,  0.0000,\n",
      "          0.0000]]), 0, 2.00584477863886, array([-0.00118332,  0.94361125, -0.05985444,  0.08708715,  0.00136317,\n",
      "        0.01341959,  0.        ,  0.        ]), False]], maxlen=100000)\n"
     ]
    }
   ],
   "source": [
    "experience = [state, action_id, reward, next_state, done]\n",
    "print(experience)\n",
    "memory.append(experience)\n",
    "print(memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `memory` reaches big enough a size, I sample a batch from it to do some learning. Let me pretend that a size of `1` is big enough for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([[-0.0006,  0.9423, -0.0599,  0.1128,  0.0007,  0.0136,  0.0000,\n",
      "          0.0000]]), 0, 2.00584477863886, array([-0.00118332,  0.94361125, -0.05985444,  0.08708715,  0.00136317,\n",
      "        0.01341959,  0.        ,  0.        ]), False]]\n",
      "tensor([[-0.0006,  0.9423, -0.0599,  0.1128,  0.0007,  0.0136,  0.0000,\n",
      "          0.0000]])\n",
      "tensor([[ 0]])\n",
      "tensor([[ 2.0058]])\n",
      "tensor([[-0.0012,  0.9436, -0.0599,  0.0871,  0.0014,  0.0134,  0.0000,\n",
      "          0.0000]])\n",
      "tensor([[ 0.]])\n"
     ]
    }
   ],
   "source": [
    "experiences = random.sample(memory, k=1)\n",
    "print(experiences)\n",
    "states = torch.from_numpy(np.vstack([e[0] for e in experiences])).float()\n",
    "actions = torch.from_numpy(np.vstack([e[1] for e in experiences])).long()\n",
    "rewards = torch.from_numpy(np.vstack([e[2] for e in experiences])).float()\n",
    "next_states = torch.from_numpy(np.vstack([e[3] for e in experiences])).float()\n",
    "dones = torch.from_numpy(np.vstack([e[4] for e in experiences]).astype(np.uint8)).float()\n",
    "print(states)\n",
    "print(actions)\n",
    "print(rewards)\n",
    "print(next_states)\n",
    "print(dones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-02 *\n",
      "       [[-0.5892,  5.7058, -9.8002,  4.9709]])\n",
      "(tensor(1.00000e-02 *\n",
      "       [ 5.7058]), tensor([ 1]))\n",
      "tensor(1.00000e-02 *\n",
      "       [ 5.7058])\n",
      "tensor(1.00000e-02 *\n",
      "       [[ 5.7058]])\n"
     ]
    }
   ],
   "source": [
    "dqn_target = QNetwork(8, 4, seed)\n",
    "temp = dqn_target(next_states)\n",
    "print(temp.detach())\n",
    "print(temp.detach().max(1))\n",
    "print(temp.detach().max(1)[0])\n",
    "Q_targets_next = dqn_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "print(Q_targets_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0623]])\n"
     ]
    }
   ],
   "source": [
    "Q_targets = rewards + (0.99 * Q_targets_next * (1 - dones))\n",
    "print(Q_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-03 *\n",
      "       [[-6.6728]])\n"
     ]
    }
   ],
   "source": [
    "Q_expected = dqn_local(states).gather(1, actions)\n",
    "print(Q_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.2808)\n"
     ]
    }
   ],
   "source": [
    "# We want to update the local DQN using the target DQN. \n",
    "loss = F.mse_loss(Q_expected, Q_targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1e-3\n",
    "\n",
    "for target_param, local_param in zip(dqn_target.parameters(), dqn_local.parameters()):\n",
    "    target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00118332  0.94361125 -0.05985444  0.08708715  0.00136317  0.01341959\n",
      "  0.          0.        ]\n",
      "2.00584477863886\n"
     ]
    }
   ],
   "source": [
    "state = next_state\n",
    "score += reward\n",
    "print(state)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
